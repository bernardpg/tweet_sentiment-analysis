{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_tweet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d4c9b609c4c5426cbd6f337b683af8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_640ab42e46fd44a3b410b967596ea141",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e355d9d52dd7473bb440be1d3a61046f",
              "IPY_MODEL_5c9c728018cb49468cb23ec2e04ad6f3"
            ]
          }
        },
        "640ab42e46fd44a3b410b967596ea141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e355d9d52dd7473bb440be1d3a61046f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7f5666e68c30460f8cc0e18dc53eba73",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a56e8a9853fe48cc9e3cd33693d296f3"
          }
        },
        "5c9c728018cb49468cb23ec2e04ad6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dcbf7e34bc444d1f950af6570d412bda",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 798kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6bbf1c0592b45a7bb1704ec7cc15571"
          }
        },
        "7f5666e68c30460f8cc0e18dc53eba73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a56e8a9853fe48cc9e3cd33693d296f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcbf7e34bc444d1f950af6570d412bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6bbf1c0592b45a7bb1704ec7cc15571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99efa59711ed46568ee5f7c0da4ac3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3ec66dbb2b1e425e83f0459f1ed882da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b6feb1bb04a47baaff011134d17d1ea",
              "IPY_MODEL_992de605c8f0481f9b51719d89172901"
            ]
          }
        },
        "3ec66dbb2b1e425e83f0459f1ed882da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b6feb1bb04a47baaff011134d17d1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5444d983999845589c8f47267f4472c4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be0a7ca66cf74e3783b87ab15eae6664"
          }
        },
        "992de605c8f0481f9b51719d89172901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7cb28db780b7449b8c9b3f52bbc6cbfe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.50kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_528705eaeaca4834a795259b8d8b52b2"
          }
        },
        "5444d983999845589c8f47267f4472c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be0a7ca66cf74e3783b87ab15eae6664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cb28db780b7449b8c9b3f52bbc6cbfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "528705eaeaca4834a795259b8d8b52b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b49795183a2c41d992b0b2246460e9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e6525fda1687467ebd8b4f409407b540",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d52f0a1aebb8456e96cb3c74deab6237",
              "IPY_MODEL_3c444104f8744e06a03624496403b2bd"
            ]
          }
        },
        "e6525fda1687467ebd8b4f409407b540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d52f0a1aebb8456e96cb3c74deab6237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7ade1f06aa6846848d18ff452bf0d96a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_342735e568364bd590a4158f8304daec"
          }
        },
        "3c444104f8744e06a03624496403b2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee7ae9b439e640ed9ca21dec94c967d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 45.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9f4cf5b8734431193806185bc921b30"
          }
        },
        "7ade1f06aa6846848d18ff452bf0d96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "342735e568364bd590a4158f8304daec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee7ae9b439e640ed9ca21dec94c967d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9f4cf5b8734431193806185bc921b30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giUId1Naqacs"
      },
      "source": [
        "##  Versions of used packages\n",
        "\n",
        "We will check PyTorch version to make sure everything work properly.\n",
        "\n",
        "We use `python 3.6.9`, `torch==1.6.0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuw-gNvjqcYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35790042-43fc-4650-ac5f-0dd5c948ab9c"
      },
      "source": [
        "!python --version\n",
        "!pip freeze | grep torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n",
            "torch==1.7.0+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMwlN8IWUGpi",
        "outputId": "6cb32fa3-40aa-40d9-d850-5fcfa428b838"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 9.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 30.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=2ac20aa0b025098bd43103773bcefe91c9c1803fec45f620138aa5e025b5cdac\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FydjP4MTWuL"
      },
      "source": [
        "## Error handling\n",
        "\n",
        "**RuntimeError: CUDA out of memory...**\n",
        "> 發生原因可能為讀取的 batch 過大或是記憶體未釋放乾淨。若縮小 batch size 後仍出現錯誤請按照以下步驟重新載入 colab。\n",
        "\n",
        "1. Click 「Runtime」\n",
        "2. Click 「Factor reset runtime」\n",
        "3. Click 「Reconnect」\n",
        "4. Reload all chunk\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiMThsYeDa2O"
      },
      "source": [
        "## Get Data\n",
        "\n",
        "請先到共用雲端硬碟將檔案`flower_data.zip`，建立捷徑到自己的雲端硬碟中。\n",
        "\n",
        "> 操作步驟\n",
        "1. 點開雲端[連結](https://drive.google.com/file/d/1rTfeCpKXoQXI978QiTWC-AI1vwGvd5SU/view?usp=sharing)\n",
        "2. 點選右上角「新增雲端硬碟捷徑」\n",
        "3. 點選「我的雲端硬碟」\n",
        "4. 點選「新增捷徑」\n",
        "\n",
        "完成以上流程會在你的雲端硬碟中建立一個檔案的捷徑，接著我們在colab中取得權限即可使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBY0b6zxI0r9"
      },
      "source": [
        "執行此段後點選出現的連結，允許授權後，複製授權碼，貼在空格中後按下ENTER，即完成與雲端硬碟連結。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCXepUIVe5iJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caab321b-286b-4404-9cbd-8febb6a8e5f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGCZQxZSfONu"
      },
      "source": [
        "!unzip -qq ./drive/My\\ Drive/twitter_sentiment.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYueKGdIHpho"
      },
      "source": [
        "## Loading the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpG2DxEqHFD-"
      },
      "source": [
        "### Custom dataset\n",
        "\n",
        "繼承自定義資料集的框架 `torch.utils.data.Dataset`，主要實現 `__getitem__()` 和 `__len__()` 這兩個方法。\n",
        "\n",
        "常使用來做到設定資料位址、設定讀取方式、子資料集的標籤和轉換條件...等。\n",
        "\n",
        "See [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) for more details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8MF0CbAMjbp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d4c9b609c4c5426cbd6f337b683af8d1",
            "640ab42e46fd44a3b410b967596ea141",
            "e355d9d52dd7473bb440be1d3a61046f",
            "5c9c728018cb49468cb23ec2e04ad6f3",
            "7f5666e68c30460f8cc0e18dc53eba73",
            "a56e8a9853fe48cc9e3cd33693d296f3",
            "dcbf7e34bc444d1f950af6570d412bda",
            "f6bbf1c0592b45a7bb1704ec7cc15571"
          ]
        },
        "outputId": "a153ce75-2084-4954-b4f9-2ff738763b48"
      },
      "source": [
        "import csv\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torchtext\r\n",
        "#from torchtext.datasets import text_classification\r\n",
        "from transformers import BertModel, BertTokenizer\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4c9b609c4c5426cbd6f337b683af8d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6bAq0n9iPRM"
      },
      "source": [
        "# sentence to word \r\n",
        "step 1 分割\r\n",
        "\r\n",
        "stpe 2 放上token \r\n",
        "\r\n",
        "step 3 設定最大詞句需要多少\r\n",
        "\r\n",
        "step 4 segment 區分不同句子\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwUE1E83_Iw8"
      },
      "source": [
        "class Twitter(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file, mode='train', transform=None):\n",
        "        \n",
        "        self.mode = mode # 'train', 'val' or 'test'\n",
        "        self.data_list = []\n",
        "        self.labels = []\n",
        "        self.transform = transform    \n",
        "        with open(csv_file, newline='') as csvfile:\n",
        "            reader = csv.DictReader(csvfile)\n",
        "            for row in reader:\n",
        "                self.data_list.append(row['text'])\n",
        "                if mode != 'test':\n",
        "                    self.labels.append(row['sentiment_label'])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #self.data_list[index] = str(self.data_list[index])\n",
        "        encoded_dict = tokenizer.encode_plus(self.data_list[index],add_special_tokens=True,max_length=64,\n",
        "                              pad_to_max_length=True,return_attention_mask=True,return_tensors='pt')\n",
        "        sentence = encoded_dict['input_ids'].flatten()\n",
        "        atten_mask= encoded_dict['attention_mask'].flatten()\n",
        "        seg_ids =encoded_dict['token_type_ids'].flatten()\n",
        "        #seg_ids = [0 for _ in range(len(sentence))]\n",
        "        #sentence = tokenizer.tokenize(self.data_list[index])\n",
        "        #sentence = ['[CLS]']+sentence+['[SEP]']\n",
        "        #seg_ids = torch.tensor(seg_ids).unsqueeze(0)\n",
        "        if self.mode == 'test':\n",
        "\n",
        "           return sentence,atten_mask,seg_ids,self.data_list[index]\n",
        "        label = torch.tensor(int(self.labels[index]))\n",
        "        #MAX_sentence =128 #一句最大128\n",
        "        #padded_sentence = sentence + ['[PAD]' for _ in range(128 - len(sentence))]\n",
        "        #attn_mask = [1 if token != '[PAD]' else 0 for token in padded_sentence]\n",
        "        # 有單詞為1 無單詞為0\n",
        "        #seg_ids = [0 for _ in range(len(sentence))] #切割不同句子\n",
        "        #token_ids = tokenizer.convert_tokens_to_ids(padded_sentence)\n",
        "        #token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
        "        #atten_mask = torch.tensor(attn_mask).unsqueeze(0)\n",
        "        return sentence,atten_mask,seg_ids,label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rYptn_YJlFX"
      },
      "source": [
        "### Instantiate dataset\n",
        "\n",
        "Let's instantiate three `FlowerData` class.\n",
        "+ dataset_train: for training.\n",
        "+ dataset_val: for validation.\n",
        "+ dataset_test: for tesing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isuz9zrfXt9U"
      },
      "source": [
        "dataset_train = Twitter('./twitter_sentiment/train.csv', mode='train')#, transform=transforms_train)\r\n",
        "dataset_val = Twitter('./twitter_sentiment/val.csv', mode='val')#, transform=transforms_test)\r\n",
        "dataset_test = Twitter('./twitter_sentiment/test.csv', mode='test')#, transform=transforms_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfKrEQsjYBSE",
        "outputId": "0645ae66-ccbe-489c-eea5-8eab91851544"
      },
      "source": [
        "print(\"The first token's shape in dataset_train :\", dataset_train.__getitem__(1)[0])\r\n",
        "print(\"There are\", dataset_train.__len__(), \"twitter text in dataset_train.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The first token's shape in dataset_train : tensor([  101,  1030,  6892, 16558,  5657,  2190,  2835,  2006,  1037,  1041,\n",
            "        16147,  2692,  2000,  2604,  2220,  1012,  3201,  1012,  2275,  1012,\n",
            "         2175,   999,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "There are 10248 twitter text in dataset_train.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vORA6qkfIj1U"
      },
      "source": [
        "### `DataLoader`\n",
        "\n",
        "`torch.utils.data.DataLoader` define how to sample from `dataset` and some other function like:\n",
        "+ `shuffle` : set to `True` to have the data reshuffled at every epoch\n",
        "+ `batch_size` : how many samples per batch to load\n",
        "\n",
        "See [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for more details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmgA5nYT3XQZ"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 設定batch數量\n",
        "batchSizeNums = 64\n",
        "\n",
        "train_loader = DataLoader(dataset_train, batch_size=batchSizeNums, shuffle=True)\n",
        "val_loader = DataLoader(dataset_val, batch_size=batchSizeNums, shuffle=False)\n",
        "test_loader = DataLoader(dataset_test, batch_size=batchSizeNums, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4atwzT3aPi3"
      },
      "source": [
        "Finally! We have made all data prepared.  \n",
        "Let's go develop our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woMVvyPUHgbX"
      },
      "source": [
        "#Deploy model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "99efa59711ed46568ee5f7c0da4ac3ce",
            "3ec66dbb2b1e425e83f0459f1ed882da",
            "8b6feb1bb04a47baaff011134d17d1ea",
            "992de605c8f0481f9b51719d89172901",
            "5444d983999845589c8f47267f4472c4",
            "be0a7ca66cf74e3783b87ab15eae6664",
            "7cb28db780b7449b8c9b3f52bbc6cbfe",
            "528705eaeaca4834a795259b8d8b52b2",
            "b49795183a2c41d992b0b2246460e9e8",
            "e6525fda1687467ebd8b4f409407b540",
            "d52f0a1aebb8456e96cb3c74deab6237",
            "3c444104f8744e06a03624496403b2bd",
            "7ade1f06aa6846848d18ff452bf0d96a",
            "342735e568364bd590a4158f8304daec",
            "ee7ae9b439e640ed9ca21dec94c967d4",
            "a9f4cf5b8734431193806185bc921b30"
          ]
        },
        "id": "g9G0LxLvVPFl",
        "outputId": "c8b149d7-387f-4652-892a-6d6226f8a06f"
      },
      "source": [
        "import torch.nn as nn \r\n",
        "import torch.nn.functional as F\r\n",
        "from transformers import BertModel, BertTokenizer,BertForSequenceClassification,BertConfig\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "num_labels=3\r\n",
        "config = BertConfig.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\r\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',config=config)\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')#, config=config)\r\n",
        "\"\"\"\r\n",
        "class SentimentClassifier(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, n_classes):\r\n",
        "    super(SentimentClassifier, self).__init__()\r\n",
        "    self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\r\n",
        "    self.drop = nn.Dropout(p=0.3)\r\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size,num_labels)\r\n",
        "  \r\n",
        "  def forward(self, input_ids, attention_mask):\r\n",
        "    _, pooled_output = self.bert(\r\n",
        "      input_ids=input_ids,\r\n",
        "      attention_mask=attention_mask\r\n",
        "    )\r\n",
        "    #output = self.drop(pooled_output)\r\n",
        "    return self.out(pooled_output)\r\n",
        "\"\"\"\r\n",
        "#model=SentimentClassifier(3)\r\n",
        "model.to(device)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99efa59711ed46568ee5f7c0da4ac3ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b49795183a2c41d992b0b2246460e9e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtOkPO6Ga0Fw"
      },
      "source": [
        "### Define loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoePct00RIFY"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "################################################################################\n",
        "# TODO: Define loss and optmizer functions\n",
        "# Try any loss or optimizer function and learning rate to get better result\n",
        "# hint: torch.nn and torch.optim\n",
        "################################################################################\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "learning_rate=1e-5\n",
        "weight_decay = 1e-2\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = optim.AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "#optimizer  = optim.Adam(bert_model.parameters(), lr=1e-5)\n",
        "################################################################################\n",
        "# End of your code\n",
        "################################################################################\n",
        "criterion = criterion.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zle9KuFcbwMP"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZFxE7Y9iLfl"
      },
      "source": [
        "#### Train function\n",
        "Let's define train function.  \n",
        "It will iterate input data 1 epoch and update model with optmizer.  \n",
        "Finally, calculate mean loss and total accuracy.\n",
        "\n",
        "Hint: [torch.max()](https://pytorch.org/docs/stable/generated/torch.max.html#torch-max)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSvNAmzcloMa"
      },
      "source": [
        "# Early Stopping\n",
        "# 來源: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4HIvlKlAirx"
      },
      "source": [
        "# mix up寫法\n",
        "# https://www.kaggle.com/c/bengaliai-cv19/discussion/128592\n",
        "# !pip install torchtoolbox\n",
        "# from torchtoolbox.tools import mixup_data, mixup_criterion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM93brDshO6E"
      },
      "source": [
        "def train(input_data, model, criterion, optimizer):\n",
        "    '''\n",
        "    Argement:\n",
        "    input_data -- iterable data, typr torch.utils.data.Dataloader is prefer\n",
        "    model -- nn.Module, model contain forward to predict output\n",
        "    criterion -- loss function, used to evaluate goodness of model\n",
        "    optimizer -- optmizer function, method for weight updating\n",
        "    token_ids,atten_mask,seg_ids,label\n",
        "    '''\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    total_count = 0\n",
        "    acc_count = 0\n",
        "    for i, data in enumerate(input_data, 0):\n",
        "        token_ids,atten_mask,labels = data[0].cuda(),data[1].cuda(),data[3].cuda()\n",
        "        #print(token_ids.size())\n",
        "        labels = labels.unsqueeze(1)\n",
        "        #print(atten_mask.size())\n",
        "        #print(labels.size())\n",
        "        ########################################################################\n",
        "        # TODO: Forward, backward and optimize\n",
        "        # 1. zero the parameter gradients\n",
        "        # 2. process input through the network\n",
        "        # 3. compute the loss\n",
        "        # 4. propagate gradients back into the network’s parameters\n",
        "        # 5. Update the weights of the network\n",
        "        ########################################################################\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(token_ids,attention_mask=atten_mask,labels=labels)\n",
        "        train_loss = outputs.loss#criterion(outputs.loss,labels)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        ########################################################################\n",
        "        # End of your code\n",
        "        ########################################################################\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        # TODO: Get the counts of correctly classified images\n",
        "        # 1. get the model predicted result\n",
        "        # 2. sum the number of this batch predicted images\n",
        "        # 3. sum the number of correctly classified\n",
        "        # 4. save this batch's loss into loss_list\n",
        "        # dimension of outputs: [batch_size, number of classes]\n",
        "        # Hint 1: use outputs.data to get no auto_grad\n",
        "        # Hint 2: use torch.max()\n",
        "        ########################################################################\n",
        "        y_pred_prob = outputs[1]\n",
        "        y_pred_label = y_pred_prob.argmax(dim=1)\n",
        "        #_, predicted = torch.max(outputs[1], 1)\n",
        "        #print(y_pred_label)\n",
        "        #print(labels)\n",
        "        total_count += len(labels)\n",
        "        acc_count += (y_pred_label == labels).int().sum()\n",
        "        loss_list.append(train_loss.item())\n",
        "        ########################################################################\n",
        "        # End of your code\n",
        "        ########################################################################\n",
        "\n",
        "    # Compute this epoch accuracy and loss\n",
        "    acc = acc_count / total_count\n",
        "    loss = sum(loss_list) / len(loss_list)\n",
        "    return acc, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmDy1GTq_H2a"
      },
      "source": [
        "#### Validate function\n",
        "Next part is validate function.  \n",
        "It works as training function without optmizer and weight-updating part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USzbBgGEoTRu"
      },
      "source": [
        "def val(input_data, model, criterion):\n",
        "    model.eval()\n",
        "    \n",
        "    loss_list = []\n",
        "    total_count = 0\n",
        "    acc_count = 0\n",
        "    with torch.no_grad():\n",
        "        for data in input_data:\n",
        "            token_ids,atten_mask,labels = data[0].cuda(),data[1].cuda(),data[3].cuda()\n",
        "            labels = labels.unsqueeze(1)\n",
        "\n",
        "            ####################################################################\n",
        "            # TODO: Get the predicted result and loss\n",
        "            # 1. process input through the network\n",
        "            # 2. compute the loss\n",
        "            # 3. get the model predicted result\n",
        "            # 4. get the counts of correctly classified images\n",
        "            # 5. save this batch's loss into loss_list attention_mask=atten_mask,\n",
        "            ####################################################################\n",
        "            outputs = model(token_ids,attention_mask=atten_mask,labels=labels)\n",
        "            val_loss = outputs.loss#criterion(outputs,labels)\n",
        "            y_pred_prob = outputs[1]\n",
        "            y_pred_label = y_pred_prob.argmax(dim=1)\n",
        "            #predicted = torch.max(outputs, 1)[1]\n",
        "            total_count += len(labels)\n",
        "            acc_count += (y_pred_label == labels).int().sum()\n",
        "            loss_list.append(val_loss.item())\n",
        "            ####################################################################\n",
        "            # End of your code\n",
        "            ####################################################################\n",
        "\n",
        "    acc = acc_count / total_count\n",
        "    loss = sum(loss_list) / len(loss_list)\n",
        "    return acc, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knXu74jCiuxP"
      },
      "source": [
        "#### Training in a loop\n",
        "Call train and test function in a loop.  \n",
        "Take a break and wait."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcVulKkFJRtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ffdd7d-7928-4658-fbd0-b92956399b28"
      },
      "source": [
        "################################################################################\n",
        "# You can adjust those hyper parameters to loop for max_epochs times           #\n",
        "################################################################################\n",
        "max_epochs = 4\n",
        "log_interval = 2              # print acc and loss in per log_interval time\n",
        "early_stopping_patience = 30\n",
        "################################################################################\n",
        "#                               End of your code                               #\n",
        "################################################################################\n",
        "train_acc_list = []\n",
        "train_loss_list = []\n",
        "val_acc_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "# initialize the early_stopping object\n",
        "early_stopping = EarlyStopping(patience=early_stopping_patience, verbose=False)\n",
        "\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    train_acc, train_loss = train(train_loader,model, criterion, optimizer)\n",
        "    val_acc, val_loss = val(val_loader, model, criterion)\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "    train_loss_list.append(train_loss)\n",
        "    val_acc_list.append(val_acc)\n",
        "    val_loss_list.append(val_loss)\n",
        "\n",
        "    if epoch % log_interval == 0:\n",
        "        print('=' * 20, 'Epoch', epoch, '=' * 20)\n",
        "        print('Train Acc: {:.6f} Train Loss: {:.6f}'.format(train_acc, train_loss))\n",
        "        print('  Val Acc: {:.6f}   Val Loss: {:.6f}'.format(val_acc, val_loss))\n",
        "    \n",
        "    # 判斷是否達到Early Stopping\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "# load the last checkpoint with the best model\n",
        "model.load_state_dict(torch.load('checkpoint.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==================== Epoch 2 ====================\n",
            "Train Acc: 30.586748 Train Loss: 0.405914\n",
            "  Val Acc: 30.256830   Val Loss: 0.406030\n",
            "EarlyStopping counter: 1 out of 30\n",
            "==================== Epoch 4 ====================\n",
            "Train Acc: 30.176424 Train Loss: 0.273423\n",
            "  Val Acc: 30.475409   Val Loss: 0.442857\n",
            "EarlyStopping counter: 2 out of 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5pW9zcKAN-2"
      },
      "source": [
        "#### Visualize accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iIOCU6cwDuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900107d2-b582-4477-9973-e561776b7c65"
      },
      "source": [
        "best_epoch = val_loss_list.index(min(val_loss_list))\n",
        "print('Early Stopping Epoch:', best_epoch)\n",
        "print('Train Acc: {:.6f} Train Loss: {:.6f}'.format(train_acc_list[best_epoch], train_loss_list[best_epoch]))\n",
        "print('  Val Acc: {:.6f}   Val Loss: {:.6f}'.format(val_acc_list[best_epoch], val_loss_list[best_epoch]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Early Stopping Epoch: 1\n",
            "Train Acc: 30.586748 Train Loss: 0.405914\n",
            "  Val Acc: 30.256830   Val Loss: 0.406030\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ifzgfp7iq2m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "0322bd9a-1353-4a4a-c0c6-512e7bc19ab9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(range(len(train_loss_list)), train_loss_list)\n",
        "plt.plot(range(len(val_loss_list)), val_loss_list, c='r')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.title('Loss')\n",
        "plt.axvline(best_epoch, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(range(len(train_acc_list)), train_acc_list)\n",
        "plt.plot(range(len(val_acc_list)), val_acc_list, c='r')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.title('Acc')\n",
        "plt.axvline(best_epoch, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEICAYAAACtaWlhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c+VnSQQQhYIJBD2VUWJiDvihhvYqtVqXbpZW61Sl6faTau2j32qVm211lp/WluLVqsFNwQVxIqVgKjsm2ASEAJhSyBku39/zCRMJiGZwCRnMvm+X6/zOpmZc5IrHga/3HPf1zHnHCIiIiIickCM1wWIiIiIiEQahWQRERERkSAKySIiIiIiQRSSRURERESCKCSLiIiIiARRSBYRERERCaKQLCIiIiISRCFZRCQCmdkGMzvD6zpERLoqhWQRERERkSAKySIinYSZJZrZQ2a2yb89ZGaJ/tcyzexVM9tpZmVmNt/MYvyv/djMSsxsj5mtMrPTvf1NREQiX5zXBYiISMh+CkwAxgIO+DfwM+DnwC1AMZDlP3YC4MxsOHADcKxzbpOZ5QOxHVu2iEjno5FkEZHO4wrgbufcVudcKfBL4Er/a9VADjDAOVftnJvvnHNALZAIjDKzeOfcBufcOk+qFxHpRBSSRUQ6j77AxoDHG/3PAfwWWAu8ZWbrzex2AOfcWmAacBew1cymm1lfRESkRQrJIiKdxyZgQMDj/v7ncM7tcc7d4pwbBEwBbq6fe+yce845d5L/XAf8pmPLFhHpfBSSRUQiV7yZJdVvwD+An5lZlpllAr8A/gZgZueb2RAzM2AXvmkWdWY23Mwm+Rf4VQL7gDpvfh0Rkc5DIVlEJHK9ji/U1m9JQCHwKfAZsBi413/sUGAOUA4sAB5zzr2Lbz7yfcA24EsgG7ij434FEZHOyXzrOkREREREpJ5GkkVEREREgigki4iIiIgEUUgWEREREQmikCwiIiIiEiTibkudmZnp8vPzvS5DRA5m1Srffvhwb+sQERE5TIsWLdrmnMtq7rWIC8n5+fkUFhZ6XYaIHMzEib793LleViEiInLYzGzjwV7TdAsRERERkSARN5IsIhHuZz/zugIREZF2p5AsIm1zxhleVyAiItLuFJJFpG2WLPHtx471tg4RETls1dXVFBcXU1lZ6XUp7SopKYnc3Fzi4+NDPkchWUTaZto0314L90REOr3i4mK6d+9Ofn4+ZuZ1Oe3COcf27dspLi5m4MCBIZ+nhXsiIiIiXVRlZSUZGRlRG5ABzIyMjIw2j5YrJIuIiIh0YdEckOsdyu+okOz35Pz1zF9T6nUZIiIiIhIBFJKBqpo6/vHRF1z5l4+47tlFFO/Y63VJIiIiIlFv586dPPbYY20+79xzz2Xnzp3tUNEBCslAQlwMr914MredPZx5q0s5/YF5PDxnDZXVtV6XJhJ5fv1r3yYiInKYDhaSa2pqWjzv9ddfp2fPnu1VFqCQ3CApPpbrTxvC27ecyhmjevO7Oas548F5vLXsS5xzXpcnEjlOOMG3iYiIHKbbb7+ddevWMXbsWI499lhOPvlkpkyZwqhRowC48MILGTduHKNHj+aJJ55oOC8/P59t27axYcMGRo4cyXe/+11Gjx7NWWedxb59+8JSm4USAM1sMvAwEAs86Zy7r5ljvgbcBTjgE+fc5f7nrwbqb9F1r3PumZZ+VkFBgSssLGzL79AuPli3jbtmLGP1lnJOGZbFnReMYnBWqtdliXjvgw98ewVlEZFOb8WKFYwcORKAX85cxvJNu8P6/Uf17cGdF4w+6OsbNmzg/PPPZ+nSpcydO5fzzjuPpUuXNrRqKysro1evXuzbt49jjz2WefPmkZGRQX5+PoWFhZSXlzNkyBAKCwsZO3YsX/va15gyZQrf+MY3Wvxd65nZIudcQXO1tdon2cxigUeBM4FiYKGZzXDOLQ84ZihwB3Cic26HmWX7n+8F3AkU4AvPi/zn7mjt53rthMGZvHbjyTy7YCO/m72ayQ+9x7dOGsgPJw0lNVHtpaUL+8lPfHv1SRYRkTAbP358o17GjzzyCC+//DIARUVFrFmzhoyMjEbnDBw4kLH+G1yNGzeODRs2hKWWUNLeeGCtc249gJlNB6YCywOO+S7waH34dc5t9T9/NjDbOVfmP3c2MBn4R1iqb2fxsTF866SBXHBUX/7vzZX8ad56Xl5cwk/OHcnUsX27RMsUERER6RpaGvHtKCkpKQ1fz507lzlz5rBgwQKSk5OZOHFis72OExMTG76OjY0N23SLUOYk9wOKAh4X+58LNAwYZmb/MbMP/dMzQj0XM7vWzArNrLC0NPLasGV1T+S3lxzFv35wAn3Skpj2/BIu/dOHYf9IQkRERKQr6d69O3v27Gn2tV27dpGenk5ycjIrV67kww8/7NDawrVwLw4YCkwEvg782cxCXnLonHvCOVfgnCvIysoKU0nhd0z/dF75wYnc99UjWFtazvm/n8/PX1nKzr1VXpcmIiIi0ulkZGRw4oknMmbMGG677bZGr02ePJmamhpGjhzJ7bffzoQJEzq0tlCmW5QAeQGPc/3PBSoG/uucqwY+N7PV+EJzCb7gHHju3EMtNhLExBiXje/POWNyeHD2Kp79cCOvfrqJ284ewaXH5hEboykYIiIiIqF67rnnmn0+MTGRN954o9nX6ucdZ2ZmsnTp0obnb7311rDVFcpI8kJgqJkNNLME4DJgRtAxr+APw2aWiW/6xXpgFnCWmaWbWTpwlv+5Ti8tOZ5fTh3Dqz88maHZ3fnJy59x4aP/YdHGiF+TKHJ4HnrIt4mIiESxVkOyc64GuAFfuF0BvOCcW2Zmd5vZFP9hs4DtZrYceBe4zTm33b9g7x58QXshcHf9Ir5oMapvD57/3gQevmwsW/dUctEfP+CWFz5h656mE8tFosLYsb5NREQkioXUJ7kjRUqf5ENRsb+G37+zlr+8v56kuFhuOmMoV5+QT3ys7tkiUWTOHN/+jDO8rUNERA5bc72Do1Vb+yQrvYVRSmIct58zglnTTuGYAenc+9oKzn14Pv9Zu83r0kTC5957fZuIiEgUU0huB4OyUnn6m8fy56sKqKyp5Yon/8sP/r6Ikp3h6dsnIiIiIu1LIbmdmBlnjurN7B+dys1nDuOdlVs5/YG5/P7tNVRW13pdnoiIiIi0QCG5nSXFx3Lj6UOZc/OpTBqRzQOzV3PW795j9vItRNp8cBEREZFIlpqa2mE/SyG5g+SmJ/PYFeP4+3eOIyEuhu/+tZBvPr2Q9aXlXpcmIiIiIkFCuZmIhNGJQzJ546aTeeaDDTw0Zw1nP/Qe3z5pED+cNISURF0O6QT+9CevKxARkShx++23k5eXx/XXXw/AXXfdRVxcHO+++y47duygurqae++9l6lTp3Z4bWoB56Gteyr5zRureGlxMX16JHHHuSOYclRfzHTXPhEREWl/jdqiTZsGS5aE9weMHdviDag+/vhjpk2bxrx58wAYNWoUs2bNIi0tjR49erBt2zYmTJjAmjVrMDNSU1MpLz+0T+HVAq4Tye6exANfO4qXvn8Cmd0TuGn6Ei594kNWbN7tdWkiBzdzpm8TERE5TEcffTRbt25l06ZNfPLJJ6Snp9OnTx9+8pOfcOSRR3LGGWdQUlLCli1bOrw2fb4fAcYNSOff15/E8wuL+O2slZz3yHyunDCAm88cTlpyvNfliTT2wAO+/QUXeFuHiIiEVwsjvu3pkksu4cUXX+TLL7/k0ksv5e9//zulpaUsWrSI+Ph48vPzqazs+DsZayQ5QsTGGJcf1593b53IFccN4NkPN3LaA3OZ/tEX1NVF1pQYERERkXC59NJLmT59Oi+++CKXXHIJu3btIjs7m/j4eN599102btzoSV0KyRGmZ3IC91w4hpk/PInBWSnc/q/PuPCx//DxFzu8Lk1EREQk7EaPHs2ePXvo168fOTk5XHHFFRQWFnLEEUfw17/+lREjRnhSl6ZbRKjRfdN44XvH8+8lm/j16yv4ymMfcMm4XP5n8giyuid6XZ6IiIhI2Hz22WcNX2dmZrJgwYJmjzvURXuHQiPJEczMuPDofrxz60S+d8ogXllSwqT75/LU+59TU1vndXkiIiIiUUshuRNITYzjjnNH8ua0Uxjbvyd3v7qc8x55nwXrtntdmnRFzz7r20RERKKYQnInMjgrlb9+azx/unIcFVU1fP3PH3L9c4vZtHOf16VJV5KX59tERCQqRNo9M9rDofyOCsmdjJlx9ug+zLn5VH50xjDmLN/C6Q/M49F317K/ptbr8qQreP553yYiIp1eUlIS27dvj+qg7Jxj+/btJCUltek83XGvkysq28uvXlvBm8u+ZEBGMndeMIpJI3p7XZZEs4kTffu5c72sQkREwqC6upri4mJP+hB3pKSkJHJzc4mPb3z/iZbuuKfuFp1cXq9kHr9yHPPXlHLXjGV86+lCJo3I5hfnjyI/M8Xr8kRERCSCxcfHM3DgQK/LiEiabhElTh6axRs3ncJPzx3JR5+Xcdbv3uO3s1ayt6rG69JEREREOh2F5CiSEBfDd08ZxDu3nMr5R+bw6LvrOP2Becz8ZFNUzzUSERERCTeF5CiU3SOJBy8dy4vXHU96cgI//MfHfP3PH7Lqyz1elyYiIiLSKYQUks1sspmtMrO1ZnZ7M69fY2alZrbEv30n4LXagOdnhLN4aVlBfi9m/vAk7r1wDCu/3MO5j8znlzOXsWtftdelSWf24ou+TUREJIq12t3CzGKB1cCZQDGwEPi6c255wDHXAAXOuRuaOb/cOZcaakHqbtE+dlRUcf9bq3juoy/olZzAjyeP4OJxucTEmNeliYiIiHiipe4WoYwkjwfWOufWO+eqgOnA1HAWKO0vPSWBX33lCGbecBL5mSn8z0uf8pU/fsAnRTu9Lk06m6ef9m0iIiJRLJSQ3A8oCnhc7H8u2EVm9qmZvWhmgbfjSjKzQjP70MwubO4HmNm1/mMKS0tLQ69e2mxMvzRevO54HvzaUZTs2MeFj/2HH7/4KdvL93tdmnQWCskiItIFhGvh3kwg3zl3JDAbeCbgtQH+YezLgYfMbHDwyc65J5xzBc65gqysrDCVJAdjZnz1mFzevfVUvnPSQF5aXMxp98/l6f98Tk1tndfliYiIiHgulJBcAgSODOf6n2vgnNvunKsfinwSGBfwWol/vx6YCxx9GPVKGHVPiuen543izWknc2RuT+6auZzzf/8+H67f7nVpIiIiIp4KJSQvBIaa2UAzSwAuAxp1qTCznICHU4AV/ufTzSzR/3UmcCKwHIkoQ7K78+y3x/P4N45hT2UNlz3xIT/8x8ds3rXP69JEREREPNHqbamdczVmdgMwC4gFnnLOLTOzu4FC59wM4EYzmwLUAGXANf7TRwJ/MrM6fIH8vsCuGBI5zIzJY3I4dVg2f5y3jsfnrePtFVu4YdIQvn3SQBLjYr0uUURERKTDtNoCrqOpBVxkKCrbyz2vLuet5VsYmJnCL84fxWkjsr0uSyLB3r2+fXKyt3WIiIgcpsNtASddUF6vZJ64qoBnvjUeA7759EK+88xCNm6v8Lo08VpysgKyiIhEPYVkadGpw7J4c9op3HHOCBas286Zv3uPB95axb6qWq9LE6889phvExERiWKabiEh27K7kv99fQWvLNlE37QkfnreKM49og9mumtflzJxom8/d66XVYiIiBw2TbeQsOjdI4mHLjuaF753PGnJCVz/3GKuePK/rN6yx+vSRERERMJKIVnabPzAXsy84UTumTqaZZt2c87D87l75nJ2V1Z7XZqIiIhIWCgkyyGJi43hyuPzeffWiXytII//98HnTLp/Lv8sLKKuLrKm8IiIiIi0lUKyHJZeKQn871ePYMb1J5HXK5nbXvyUix7/gE+Ld3pdmoiIiMgh08I9CZu6Ose/Pi7hvjdWsr1iP5cdm8dtZ4+gV0qC16WJiIiINKGFe9IhYmKMi8fl8s6tp/KtEwfyQmExE3/7Ln9dsIGa2jqvyxMREREJmUKyhF2PpHh+fv4o3rzpZI7ITeMX/17G+b9/n48+L/O6NAmH++/3bSIiIlFMIVnazdDe3fnbt4/jsSuOYfe+ar72pwXcNP1jtuyu9Lo0ORyvvurbREREophCsrQrM+PcI3J4+5aJ3DhpCG8s/ZJJ98/l8XnrqKrRFAwRERGJTArJ0iG6JcRy81nDmfOjUzl+cCb3vbGSyQ+9x7zVpV6XJiIiItKEQrJ0qP4ZyTx5dQH/75vH4oCrn/qI7/61kKKyvV6XJiIiItJAIVk8cdrwbN6cdjI/njyC/6zdxukPzuPB2avZV1XrdWnSmm7dfJuIiEgUU59k8dyXuyr59esrmPHJJvr17MbPzx/J2aP7YGZelyYiIiJRTH2SJaL1SUvika8fzfRrJ9A9KY7r/raYK//yEWu37vG6NBEREemiFJIlYkwYlMGrPzyJX04ZzafFO5n80Hx+9dpy9lRWe12aBLrnHt8mIiISxRSSJaLExcZw9Qn5vHvrRC4el8uT73/OpAfm8dKiYurqImtqUJf19tu+TUREJIopJEtEykhN5L6LjuSVH5xIv57duOWfn3DJnxawtGSX16WJiIhIFxBSSDazyWa2yszWmtntzbx+jZmVmtkS//adgNeuNrM1/u3qcBYv0e+ovJ786/sn8H8XH8nG7RVc8If3+cnLn7Gjosrr0kRERCSKxbV2gJnFAo8CZwLFwEIzm+GcWx506PPOuRuCzu0F3AkUAA5Y5D93R1iqly4hJsb4WkEeZ4/uw8Nz1vDMgg28/tlmbjlrOJeP709sjLpgiIiISHiFMpI8HljrnFvvnKsCpgNTQ/z+ZwOznXNl/mA8G5h8aKVKV5fWLZ5fXDCK1288mZF9evDzV5Zywe/fp3BDmdeldS0ZGb5NREQkioUSkvsBRQGPi/3PBbvIzD41sxfNLK8t55rZtWZWaGaFpaW6TbG0bHif7jz33eP4w+VHs2NvFRc/voAfPb+ErbsrvS6ta3jpJd8mIiISxcK1cG8mkO+cOxLfaPEzbTnZOfeEc67AOVeQlZUVppIkmpkZ5x/Zl7dvOZXrTxvMa59u5rT75/LEe+uoqqnzujwRERHp5EIJySVAXsDjXP9zDZxz251z+/0PnwTGhXquyOFITojjtrNH8NaPTuG4QRn8+vWVTH74Pd5brU8k2s0dd/g2ERGRKBZKSF4IDDWzgWaWAFwGzAg8wMxyAh5OAVb4v54FnGVm6WaWDpzlf04krPIzU3jqmmN56poCauscVz31Ed97tpCisr1elxZ9FizwbSIiIlGs1e4WzrkaM7sBX7iNBZ5yzi0zs7uBQufcDOBGM5sC1ABlwDX+c8vM7B58QRvgbuecVllJu5k0ojcnDM7kL+9/zh/eWcsZq+bx/YmDue7UwSTFx3pdnoiIiHQS5lxk3cWsoKDAFRYWel2GRIFNO/fx69dX8Oqnm8lN78bPzhvF2aN7Y6aWcYdl4kTffu5cL6sQERE5bGa2yDlX0NxruuOeRK2+Pbvxh8uP4bnvHkdKQhzX/W0RVz31EWu3lntdmoiIiEQ4hWSJeicMzuS1G0/izgtGsaRoJ5Mfeo9fv76C8v01XpfWOeXm+jYREZEopukW0qVsK9/P/725khcKi8nunsgd547gwrH9NAVDRESkC9J0CxG/zNRE/u/io3j5ByeQk5bEj57/hEseX8CyTbu8Lk1EREQiiEKydElH90/n5R+cyG8uOoL12yq44Pfv87NXPmPn3iqvS4t806b5NhERkSjWags4kWgVE2Ncemx/Jo/O4XdzVvPXBRt47dPN3Hr2cC47tj+xMZqC0awlS7yuQEREpN1pJFm6vLTkeO6aMprXbjyZob2789OXlzL10fdZtHGH16WJiIiIRxSSRfxG5vTg+Wsn8MjXj2bbniou+uMH3PLCJ2zdU+l1aSIiItLBFJJFApgZU47qy9u3nMr3Jw5mxiclTLp/Hk/OX091bZ3X5YmIiEgHUUgWaUZKYhw/njyCt350KgX56dz72grOeXg+/1m7zevSvDdsmG8TERGJYuqTLNIK5xxvr9jK3a8u54uyvZwzpg8/PW8kuenJXpcmIiIih6GlPsnqbiHSCjPjjFG9OWloJk/OX88f3l3Lu6u28oOJQ7j2lEEkxcd6XaKIiIiEmaZbiIQoKT6WGyYN5e1bJnL6iN48OHs1Z/5uHrOXbyHSPpFpV9de69tERESimEKySBv169mNR684hue+cxxJcbF896+FXPP/FrK+tNzr0jrG6tW+TUREJIopJIscohOGZPL6TSfz8/NHsXjjDs5+6D3ue2MlFftrvC5NREREDpNCsshhiI+N4dsnDeSdWycydWw/Hp+3jkkPzOXfS0q61hQMERGRKKOQLBIGWd0Tuf+So/jXD04gu3sSN01fwqVPfMiKzbu9Lk1EREQOgUKySBgd0z+dV64/kf/96hGs2bKH8x6Zz53/XsquvdVelxY+Y8f6NhERkSimPski7WTn3ioenL2av324kZ7JCdx29nC+VpBHbIx5XZqIiIjQcp9kjSSLtJOeyQncPXUMr/7wZIZkpXLHvz7jK4/9h4+/2OF1aSIiItKKkEKymU02s1VmttbMbm/huIvMzJlZgf9xvpntM7Ml/u3xcBUu0lmM6tuD5783gYcvG8uW3ZV85bEPuPWfn1C6Z7/XpR2ab3zDt4mIiESxVu+4Z2axwKPAmUAxsNDMZjjnlgcd1x24Cfhv0LdY55zTBEbp0syMqWP7cfrI3vzhnbX85f31zFr6JdPOHMZVxw8gPrYTfahTXOx1BSIiIu0ulP8zjwfWOufWO+eqgOnA1GaOuwf4DVAZxvpEokpqYhy3nzOCN6edwjED0rnn1eWc98h8Pli7zevSREREJEAoIbkfUBTwuNj/XAMzOwbIc8691sz5A83sYzObZ2YnN/cDzOxaMys0s8LS0tJQaxfptAZnpfL0N4/lz1cVsK+6lsuf/C/X/30xJTv3eV2aiIiIEIaFe2YWAzwI3NLMy5uB/s65o4GbgefMrEfwQc65J5xzBc65gqysrMMtSaRTMDPOHNWb2T86lZvPHMacFVs4/YG5/OGdNVRW13pdnoiISJfW6pxkoATIC3ic63+uXndgDDDXzAD6ADPMbIpzrhDYD+CcW2Rm64BhQOT1ePvVr6C2FvLyGm/JyV5XJlEuKT6WG08fyleP6cevXlvB/W+t5oXCYu68YBSnj+ztdXlNHX+81xWIiIi0u1b7JJtZHLAaOB1fOF4IXO6cW3aQ4+cCtzrnCs0sCyhzztWa2SBgPnCEc67sYD/Psz7JRx4Jn33W9PlevZoG57w8yM09sE9M7Ph6JWq9v2Ybd85YyrrSCk4bnsUvLhjNwMwUr8sSEREJr9paKC2FzZt9mSozs8NLaKlPcqsjyc65GjO7AZgFxAJPOeeWmdndQKFzbkYLp58C3G1m1UAdcF1LAdlTn34K+/f7Vu4XFTW/ffABlDVTfnZ280G6fuvbF+JCGbQXgZOGZvLGTafwzAcbePjtNZz9u/f4zskDuf60IaQk6s+RiIhEMOdg92748svG2+bNTZ8rLYW6Ot95zz4bce1Fdce9tqqoaDlIFxXBnj2Nz4mJgZycloN0796+40QCbN1dyX1vruRfi0vo0yOJn5w3kguOzME/tckbF13k27/0knc1iIhIx6qqgi1bmg+7wUG4splGZ/Hx0KfPgS0np/Hj8eOhX7+m57WzlkaSFZLbw65dLYfooqKmf4Di431/OIKncwRumZngZTgSzyzaWMYv/r2MZZt2c9zAXvxy6mhG9GmyBrZjTJzo28+d683PFxGR8Kir831CHsqob3OfpIMvmwSG3YMF4fT0iMwwCsmRxjnYvt0Xlg82Kl1cDNXVjc9LSmo+PAduaWkR+YdQDl9tnWP6wi/47axV7Kms4coJA/jRmcNI6xbfsYUoJIuIRLa9ew8edgOD8JYtUFPT9Pxu3RoH3OBR3/otOxsSEjr+9wsjheTOqK4Otm5teTR606YDc3nqpaa2HKLz8iBFi8A6sx0VVTwwexXP/fcL0pMT+J/Jw7lkXB4xMR30jyOFZBGRjldT45vDG8qob/C0T/BN6ezdO7RR39TULjPgppAcrWpqfG+OloL0li1Nz0tPP/iUjvrnk5I6/veRNllasou7ZiyjcOMOjspN45dTxzA2r2f7/2CFZBGR8Ahc5NbaqG9pqe/4YGlpLQfe+i0zE2JjO/53jHCH1d1CIlhc3IFgezBVVVBScvAQ/d//+qZ+BMvKar1jR3wHf8wvjYzpl8Y/rzueV5aU8OvXV3Lho//h0oI8bps8nMzUdmxLePrp7fe9RUSiwf79vkGqUEZ9W1rklpMDAwbAccc1H4R79/ZNjZB2oZFk8c1daq1jx+7djc8xO3jHjvoR6j599K/WDrKnsprfv7OWp97/nG4Jsdx85jCunDCAuFh1TBERCYvARW6tjfru2NH892hukVtzo74RusgtGmm6hRy+3bubX1wY+Hjv3sbnxMX5RpxbGpHOytJfBGG0dms5v5y5jPlrtjGiT3fumjKaCYMyvC5LRCRyVVS03M6sfmttkdvBFrfVB+HsbH0CG4EUkqX9Oef7l3NLo9HFxb7pH4ESE1vv2NGzp4J0GzjnmLVsC/e8upySnfs4/8gcfnreSHLSwvSR3Dnn+PZvvBGe7yciEm71i9xaGvGtD8Ll5U3PP9git+aCcBda5BaNFJIlMtTV+f7Saq1jR21t4/NSUg4+paN+697dm98pglVW1/LHuet4fN46Ysy4YdIQvnPyQBLjDnMKjBbuiYgXnPPdhyCUUd9QFrkdbOQ3JwcyMjRdsItQSJbOo7bW9xdcS0H6yy+b/uWXltbyaHRubpdd3FBUtpd7X1vOrGVbyM9I5s4LRnPaiOxD/4YKySISTvWL3Fob9T3YIreEhNDammmRmzRDIVmiS1WVb8S5pSC9bVvT8zIzWw7S/fpF9Xyx91aXctfMZawvreD0Edn84oJRDMg4hJ7ZCski0pq6Ol/npFBGfUNZ5NbSqK+m5MlhUEiWrmffvpFiz0AAABeaSURBVOY7dgQ+t3Nn43PMfCMNLQXpnJxO/RFcVU0dT3/wOQ/PWUN1rePaUwbxg9MGk5zQhm6QCskiXVf9IrfWRn0PtsgtObnlwBt4J7coHrSQyKGQLNKcPXtab31XUdH4nNjY0Dp2xER267Utuyu5742VvPxxCX3TkvjpeaM494g+WCijMfff79vfemv7FikiHaOmxneH11BGfUNZ5NZSlwetH5EIo5Asciic8402t9axY//+xuclJLTcsSM3F3r1ioiPBxduKOPOfy9j+ebdHD8og19OHc2w3vqfmEinF7zIraWR35YWubXW1qxPHy1yk05NIVmkvTh3oGPHwUalS0qafuyYnNx667sePTrkV6itczz30RfcP2sV5ftruPr4fKadOZQeSfqoUyTiVFY2fye35oJw8D/goflFbs0FYS1yky5CIVnES7W1vv+ptTQivXlz05GcHj1a79iRnBy2Mssqqrj/rVX846MvyEhJ4H8mj+DiY3KJiQka8dacZJHwCl7k1tKob0uL3EIZ9dUiN5FGFJJFIl11dcsdO4qLfXMGg2VktHxr8Nxc38hRGywt2cUv/r2UxV/sZGxeT+6eOpojc3seOEAhWaQp53xht7b2wFZT4+u009qo75YtTfvDQ/OL3JoLwlrkJnLIFJJFokFlpW/qRksj0s2NMoXSsSOucXeLujrHyx+X8L9vrGR7xX4uLcjjtrOHk5GaqJAcbYKDXXNbTU3rx3h1XKTUVlcX2n/v2FhfqA1l1Dc1tX2vvYi0GJLb0PdJRDyVlASDB/u2gykvP/jc6JUrYfbspqvTY2KadOyIycvjorw8Jk/M4YnP43ms8Ate/2wzt5w1nKtcBHxaGzhqFykhKVJ+ZluP6yxiYnwBs6UtLq71YwKPS0gI3/c62GsZGY0DsBa5iXQaGkkW6UrqV7w31zc6cAu6q5WLj6c0LYvPk9IZtrOEpMR4qk4/kx7xMVidB0Ev1FG7SHCoASwcIc3Lnxnu+j3/l5mIRCONJIuIj5lv4U7PnnDEEc0f45xvEVFAaLaiIrKKiohbuQ4rq6OqvILyN2ZTHhtDbEI8iYnxJCYmkJQUT8zBQk9Lo3bRGgwjvF+2iIgcXEgh2cwmAw8DscCTzrn7DnLcRcCLwLHOuUL/c3cA3wZqgRudc7PCUbiItBMz30r5zEw4+ugDTwO9AOccG7bvpXBDGYu/2MGijTtYvcU3hSM2xhiZ051x/dM5ZkA64wak069nt9BuUiIiIhJBWp1uYWaxwGrgTKAYWAh83Tm3POi47sBrQAJwg3Ou0MxGAf8AxgN9gTnAMOdc7cF+nqZbiES4vXt9+4D2c7v2VvNx0Q4Wb9xB4cYdLCnayd4q39u8d49ECgb0agjNo3J6kBCnEVYREfHe4U63GA+sdc6t93+z6cBUYHnQcfcAvwFuC3huKjDdObcf+NzM1vq/34K2/QoiEjHOPde3D+hukZYcz8Th2Uwcng1ATW0dK7/c0zDSXLhhB699thmAxLgYjsrtyTED0ikY4Btx7pXStjZ1IiIi7S2UkNwPKAp4XAwcF3iAmR0D5DnnXjOz24LO/TDo3H7BP8DMrgWuBejfv39olYtIxIqLjWFMvzTG9EvjquPzAfhyV2VDaF60cQd/eX89j8/zfZI1KDOlYaS5YEA6g7NSm97EREREpAMd9sI9M4sBHgSuOdTv4Zx7AngCfNMtDrcmEYk8fdKSOPeIHM49IgeAyupaPi3e1RCa31m5lRcXFQPQIynOF5r7+4LzUXk9SUnUOmMREek4ofxfpwTIC3ic63+uXndgDDDXvzinDzDDzKaEcK6IdFFJ8bGMH9iL8QN7Ac0vCJy7qhTQgkAREel4oYTkhcBQMxuIL+BeBlxe/6JzbheQWf/YzOYCt/oX7u0DnjOzB/Et3BsKfBS+8kUkWpgZAzNTGJiZwiUFvn9bBy8I/OeiYp5ZsBHQgkAREWlfrYZk51yNmd0AzMLXAu4p59wyM7sbKHTOzWjh3GVm9gK+RX41wPUtdbYQkU7gmms67EdpQaCIiHhFd9wTkU4teEHgsk27qK7VgkAREWldSy3gFJJFpG22bfPtMzNbPs4jwQsCF3+xg7KKKkALAkVEpDHdllpEwufii337gD7JkUQLAkVEJBwUkkUkqmlBoIiIHAqFZBHpcg5lQeC4/PSGEWctCBQRiX4KySLS5YVyh8An56/nj1oQKCLSZSgki4g0Q3cIFBHp2vS3uIi0zfe/73UFntCCQBGRrkUt4EREwiR4QeCSop3srfLdP6lPjyTGDUjXgkARkQiiFnAiEj5FRb59Xp63dUQgLQgUEYkeGkkWkbaZONG3j9A+yZFOdwgUEYkcGkkWEYkQWhAoItI56G9bEREPaUGgiEhkUkgWEYkgbb1DoBYEioi0D4VkEZEIpwWBIiIdTwv3RKRtZs707S+4wNs6pJFQFgQW+EebtSBQRMSnpYV7CskiIlEoeEHg4i92UFZRBWhBoIhIPXW3EJHwWbXKtx8+3Ns6pEVaECgicng0kiwibaM+yVFDdwgUka5OI8kiItJEmxcE5vVk3AAtCBSRrkEhWUREAIiLjWFMvzTG9EvjquPzgaYLAp+cv54/akGgiHQBIYVkM5sMPAzEAk865+4Lev064HqgFigHrnXOLTezfGAF4J/EyIfOuevCU7qIiLS3Q75DYH46R+VqQaCIdF6t/u1lZrHAo8CZQDGw0MxmOOeWBxz2nHPucf/xU4AHgcn+19Y558aGt2wREfGCFgSKSFcRyj/xxwNrnXPrAcxsOjAVaAjJzrndAcenAJG1GlBEwudnP/O6AokgukOgiESrUEJyP6Ao4HExcFzwQWZ2PXAzkABMCnhpoJl9DOwGfuacm9/MudcC1wL0798/5OJFxANnnOF1BRLhtCBQRKJBqy3gzOxiYLJz7jv+x1cCxznnbjjI8ZcDZzvnrjazRCDVObfdzMYBrwCjg0aeG1ELOJEIt2SJbz9Ws6jk0LV2h8Bx/pFmLQgUkfZ0uC3gSoC8gMe5/ucOZjrwRwDn3H5gv//rRWa2DhgGKAWLdFbTpvn26pMsh6G1BYFvr9zKP7UgUEQ8FMrfMguBoWY2EF84vgy4PPAAMxvqnFvjf3gesMb/fBZQ5pyrNbNBwFBgfbiKFxGR6KAFgSISaVoNyc65GjO7AZiFrwXcU865ZWZ2N1DonJsB3GBmZwDVwA7gav/ppwB3m1k1UAdc55wra49fREREoocWBIqI13RbahFpG92WWiJEcwsCS3buA7QgUERCo9tSi4hI1DmUOwRqQaCIhEojySLSNh984NufcIK3dYiEIHhB4OIvdlBWUQVoQaCIaCRZRMJJ4Vg6kcNZEFiQ34u+aUlaECjSRWkkWUTaRiPJEmWCFwQuKdrJ3qpaQAsCRaJdSyPJCski0jZauCdRTgsCRboOTbcQEREJkRYEiggoJIuIiLTqUO8QODKnB4OzU8lL70ZcrKZpiHQmCskiIiJt1JYFgQDxscaAjBQGZ6UwOCvVt2WnMigrhR5J8V79GiLSAoVkERGRw9TcHQJ3V1azbms560orWFdazvpS39dvr9hKTd2B9UBZ3RObhufMFPr17KZpGyIeUkgWkbZ56CGvKxDpFHokxXN0/3SO7p/e6Pnq2jqKyvY2hOd1W8tZv62CVz/dzK591Q3HJcXHMDAz9UCA9ofnQVkpJCfof98i7U3dLURERCKAc46yiqpG4XldqS9AF5XtJWDwmX49uzEoIDzXB+ns7onq6yzSBupuISLhM2eOb3/GGd7WIRJlzIyM1EQyUhMb5jrXq6yuZeP2vU3C8z8Li6jw93QGSE2MazTyPDgrhUFZqQzISCYxLrajfyWRTk0jySLSNuqTLBIxnHNs2b3fF54bAnQF60vL2bSrsuG4GIP+vZKbjDwPykpVn2fp0jSSLCIiEoXMjD5pSfRJS+LEIZmNXqvYX8Pn2yoahed1peXMX7uNqpq6huPSk+MDFg0eCM9qWyddnUKyiIhIFEpJjGu4KUqg2jrHpp37WBsUnt9euZXnC/c3HBcfa+RnpDQKz74AnUJ3ta2TLkAhWUREpAuJjTHyeiWT1yuZ04ZnN3pt195q1m1rHJ5Xb93DnBVbGrWty+6e2Gx47pumtnUSPRSSRUREBIC05HiO6Z/OMc20rfuibG+j8LyutJwZSzaxu7Km4bik+BgGZQbPe05hUGYq3RK0cFA6F4VkEWmbP/3J6wpEpIPFx8Y0jBgHcs6xvaKqSXj+pGgnr366CRfUti44PA/JSiVLbeskQikki0jbDB/udQUiEiHMjMzURDJTEzluUEaj1yqra9mwvYJ1Ww+E53Wl5RRuKGNvQNu67olxDAoIz/X7ARkpJMRp4aB4RyFZRNpm5kzf/oILvK1DRCJaUnwsI/r0YESfHo2ed87x5e7KJuH5g7Xb+dfikobjYmPM37au8bznwVmppKttnXSAkEKymU0GHgZigSedc/cFvX4dcD1QC5QD1zrnlvtfuwP4tv+1G51zs8JXvoh0uAce8O0VkkXkEJgZOWndyEnrxklDG7etK99fw+eljcPzuq0VvLd6G1W1B9rW9UpJaBSeB2f75j3nqm2dhFGrIdnMYoFHgTOBYmChmc2oD8F+zznnHvcfPwV4EJhsZqOAy4DRQF9gjpkNc87VIiIiIhIgNTGOI3LTOCK3adu6kh37moTn2cu3ML2iqOG4hNgY8jOTm4Rnta2TQxHKSPJ4YK1zbj2AmU0HpgINIdk5tzvg+BSgfqr+VGC6c24/8LmZrfV/vwVhqF1ERES6gNgYo39GMv0zkjltROO2dTv3VjVaNLhuawWrvtzDW8u3UBvQtq53j8QD4dl/u+7B2ank9EhS2zppVighuR9QFPC4GDgu+CAzux64GUgAJgWc+2HQuf2aOfda4FqA/v37h1K3iIiICD2TExg3IIFxAxq3rauq8betCwjP60rLeWVJCXsC2tZ1i49tmOscPPqcFK+2dV1Z2BbuOeceBR41s8uBnwFXt+HcJ4AnAAoKClwrh4uIiIi0KCEuhiHZqQzJbtq2rrR8P+vrR5/94XnxFzuYGdC2zszfti4oPA/OTiErVW3ruoJQQnIJkBfwONf/3MFMB/54iOeKSKR79lmvKxAROWRmRnb3JLK7JzGhmbZ1n29rHJ7XlZbz0edl7KsOaFuXFNckPA/JTqF/L7WtiyahhOSFwFAzG4gv4F4GXB54gJkNdc6t8T88D6j/egbwnJk9iG/h3lDgo3AULiIeyctr/RgRkU4oKT6WkTk9GJnTuG1dXZ2/bV1p41t2v7+2lJcWFzccFxtjDOiV7J/vnMLgzAO37u6ZrLZ1nU2rIdk5V2NmNwCz8LWAe8o5t8zM7gYKnXMzgBvM7AygGtiBf6qF/7gX8C3yqwGuV2cLkU7u+ed9+0sv9bYOEZEOEhNj9O3Zjb49u3Hy0KxGr+2prG529Pm91aWN2tZlpCQ0jDwH9nzOTU8mVgsHI5I5F1lTgAsKClxhYaHXZYjIwUyc6NvPnetlFSIiEa2mto7iHftYv6086MYpFZRVVDUclxAXw8CMlIbwXB+gB2Wlkpqoe761NzNb5JwraO41/dcXERERCbO42BjyM1PIz0xh0ojGr+2oqGoSnlds3sOsZY3b1vXpkdQkPA/OSiUnLUkLBzuAQrKIiIhIB0pPSWBcSi/GDejV6Pn9NbV8sX1v477PpRW8vLiEPfsPtK1LTmjctq7+64GZalsXTgrJIiIiIhEgMS6Wob27M7R390bPO+co3bO/SXgu3LCDfy/Z1HCcGeSmd2sSngdnpZKZmqDR5zZSSBYRERGJYGZGdo8ksnskcfzgxm3r9lXVsn5b+YG+z6UVrNtazofrt1NZfWDhYI+kOAZnpzYJ0AMykomPVdu65mjhnoi0zbZtvn1mprd1iIjIQdXVOTbt2se60grWB911cOue/Q3Hxflv+R0cnodkpZKWHO/hb9AxtHBPRMJH4VhEJOLFxBi56cnkpidz6rDGbet2V1azvpnwPHfVVqprDwyeZqYm+Ho+Z6UyOGDqRr/0bl2ibZ1Csoi0zdNP+/bXXONlFSIicoh6JMUzNq8nY/N6Nnq+praOoh37moTnN5ZuZufe6objEuJiGJSZ0hCeBwWMQqdEUds6TbcQkbZRn2QRkS6nrKKKdaXl/gBd4b/zYDlflO0loGsdOWlJB0aes1MZ5L/rYJ8ekdm2TtMtREREROSQ9UpJoFdKL47Nb9q2buP2vazbWs76bQfC80uLSygPaFuXkhDrH3Guv+OgLzznZ0Ru2zqFZBERERE5JIlxsQzr3Z1hzbSt27pnvy80B4TnhRt28EpQ27q89GR+et5Izh7dp6PLb5FCsoiIiIiElZnRu0cSvXskccKQxgu+91bVNLSsq99npiZ4VOnBKSSLiIiISIdJTohjTL80xvRL87qUFikki0jbvP661xWIiIi0O4VkEWmb5GSvKxAREWl3ug+hiLTNY4/5NhERkSimkCwibfPCC75NREQkiikki4iIiIgEUUgWEREREQmikCwiIiIiEkQhWUREREQkiDnnvK6hETMrBTZ69OMzgW0e/Wxpnq5JZNJ1iTy6JpFJ1yXy6JpEJq+uywDnXFZzL0RcSPaSmRU65wq8rkMO0DWJTLoukUfXJDLpukQeXZPIFInXRdMtRERERESCKCSLiIiIiARRSG7sCa8LkCZ0TSKTrkvk0TWJTLoukUfXJDJF3HXRnGQRERERkSAaSRYRERERCaKQLCIiIiISpEuGZDObbGarzGytmd3ezOuJZva8//X/mll+x1fZtYRwTa4xs1IzW+LfvuNFnV2JmT1lZlvNbOlBXjcze8R/zT41s2M6usauJoRrMtHMdgW8T37R0TV2RWaWZ2bvmtlyM1tmZjc1c4zeLx0oxGui90sHMrMkM/vIzD7xX5NfNnNMROWvLheSzSwWeBQ4BxgFfN3MRgUd9m1gh3NuCPA74DcdW2XXEuI1AXjeOTfWvz3ZoUV2TU8Dk1t4/RxgqH+7FvhjB9TU1T1Ny9cEYH7A++TuDqhJoAa4xTk3CpgAXN/M32F6v3SsUK4J6P3SkfYDk5xzRwFjgclmNiHomIjKX10uJAPjgbXOufXOuSpgOjA16JipwDP+r18ETjcz68Aau5pQrol0MOfce0BZC4dMBf7qfD4EeppZTsdU1zWFcE3EA865zc65xf6v9wArgH5Bh+n90oFCvCbSgfx/9sv9D+P9W3D3iIjKX10xJPcDigIeF9P0jdNwjHOuBtgFZHRIdV1TKNcE4CL/x5Qvmllex5QmLQj1uknHOt7/ceYbZjba62K6Gv/Hw0cD/w16Se8Xj7RwTUDvlw5lZrFmtgTYCsx2zh30fRIJ+asrhmTpnGYC+c65I4HZHPiXpogcsBgY4P848/fAKx7X06WYWSrwEjDNObfb63qk1Wui90sHc87VOufGArnAeDMb43VNLemKIbkECByFzPU/1+wxZhYHpAHbO6S6rqnVa+Kc2+6c2+9/+CQwroNqk4ML5b0kHcg5t7v+40zn3OtAvJllelxWl2Bm8fjC2N+dc/9q5hC9XzpYa9dE7xfvOOd2Au/SdI1FROWvrhiSFwJDzWygmSUAlwEzgo6ZAVzt//pi4B2nu660p1avSdDcvSn45peJt2YAV/lX7U8AdjnnNntdVFdmZn3q5++Z2Xh8f8frH/jtzP/f/C/ACufcgwc5TO+XDhTKNdH7pWOZWZaZ9fR/3Q04E1gZdFhE5a84r36wV5xzNWZ2AzALiAWecs4tM7O7gULn3Ax8b6xnzWwtvkUyl3lXcfQL8ZrcaGZT8K1YLgOu8azgLsLM/gFMBDLNrBi4E99CC5xzjwOvA+cCa4G9wDe9qbTrCOGaXAx838xqgH3AZfoHfoc4EbgS+Mw/3xLgJ0B/0PvFI6FcE71fOlYO8Iy/o1UM8IJz7tVIzl+6LbWIiIiISJCuON1CRERERKRFCskiIiIiIkEUkkVEREREgigki4iIiIgEUUgWEREREQmikCwiIiIiEkQhWUREREQkyP8HAFNuq05+wYQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMYSgO5viYOk"
      },
      "source": [
        "### Predict Result\n",
        "\n",
        "預測`test`並將結果上傳至Kaggle。[**連結**](https://www.kaggle.com/t/a16786b7da97419f9ba90b495dab08aa)\n",
        "\n",
        "執行完畢此區的程式碼後，會將`test`預測完的結果存下來。\n",
        "\n",
        "上傳流程\n",
        "1. 點選左側選單最下方的資料夾圖示\n",
        "2. 右鍵「result.csv」\n",
        "3. 點選「Download」\n",
        "4. 至連結網頁點選「Submit Predictions」\n",
        "5. 將剛剛下載的檔案上傳\n",
        "6. 系統會計算並公布其中70%資料的正確率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiyK25P6KXrn"
      },
      "source": [
        "def predict(input_data, model):\n",
        "    model.eval()\n",
        "    output_list = []\n",
        "    text = []\n",
        "    with torch.no_grad():\n",
        "        for data in input_data:\n",
        "            token_ids,atten_mask,segments_tensors,senten= data[0].cuda(),data[1].cuda(),data[2].cuda(),data[3]\n",
        "            print(segments_tensors)\n",
        "            #labels = labels.unsqueeze(1)\n",
        "            #segments_tensors = segments_tensors.flatten()\n",
        "            outputs = model(token_ids,token_type_ids=segments_tensors,attention_mask=atten_mask)\n",
        "            y_pred_prob = outputs[0]\n",
        "            y_pred_label = y_pred_prob.argmax(dim=1)\n",
        "            #outputs = model(images)\n",
        "            #_, predicted = torch.max(outputs.data, 1)\n",
        "            output_list.extend(y_pred_label.to('cpu').numpy().tolist())\n",
        "            for r in (senten):\n",
        "              text.append(r)\n",
        "    return output_list,text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I0LN7HwpnsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2829ab-bc9b-4886-da09-915b7d12775d"
      },
      "source": [
        "output_csv,text = predict(test_loader, model)\n",
        "with open('result.csv', 'w', newline='') as csvFile:\n",
        "    writer = csv.DictWriter(csvFile, fieldnames=['index','sentiment_label'])\n",
        "    writer.writeheader()\n",
        "    idx = 0\n",
        "    #'text' :text[idx] ,\n",
        "    for result in output_csv:\n",
        "        writer.writerow({'index':idx,'sentiment_label':result})\n",
        "        idx+=1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}